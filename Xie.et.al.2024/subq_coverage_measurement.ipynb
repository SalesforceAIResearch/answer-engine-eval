{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494dc5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from pprint import pprint\n",
    "import re\n",
    "import copy\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1476faa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "import time\n",
    "SLEEP_TIME = 1\n",
    "\n",
    "def gpt4(input_text, prior_messages=None):\n",
    "    gpt4_kwargs = {\n",
    "        \"model\": \"gpt-4-turbo\",\n",
    "        \"temperature\": 0,\n",
    "    }\n",
    "    if prior_messages is None:\n",
    "        messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\n",
    "    else:\n",
    "        messages = copy.deepcopy(prior_messages)\n",
    "    messages.append({\"role\": \"user\", \"content\": input_text})\n",
    "    while True:\n",
    "        try:\n",
    "            response = client.chat.completions.create(messages=messages, **gpt4_kwargs)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(\"-\"*30)\n",
    "            print(e)\n",
    "            if type(e).__name__ == \"RateLimitError\":\n",
    "                print(f\"Sleep for {SLEEP_TIME}......\")\n",
    "                time.sleep(SLEEP_TIME)\n",
    "            print(\"-\"*30)\n",
    "    output_text = response.choices[0].message.content\n",
    "    messages.append({\"role\": \"assistant\", \"content\": output_text})\n",
    "    return output_text, messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44bb853-8b2d-41d6-991d-f465cbdf469e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    excel_file = pd.ExcelFile(path)\n",
    "    sheet_names = excel_file.sheet_names\n",
    "    all_sheets_data = {sheet: excel_file.parse(sheet) for sheet in sheet_names}\n",
    "    return all_sheets_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d02dff6-c3c0-43ef-8ccb-dc2f821b6b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = load_data(\"Answerability Annotation.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3039d85c-c03f-4152-98a0-dfea82e78dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"You are given a passage and a list of questions. For each question, determine if there exists any part of the passage that can answer the question.\n",
    "If the question is answered, identify the text span that answers the question; if the question is unanswered, just return \"None\".\n",
    "\n",
    "Organize your response in JSON-format, shaped as the following:\n",
    "\n",
    "[\n",
    "    {\n",
    "        \"question\": QUESTION_1,\n",
    "        \"judgment\": \"answered\",\n",
    "        \"text_span\", YOUR_IDENTIFIED_TEXT_SPAN\n",
    "    },\n",
    "    {\n",
    "        \"question\": QUESTION_2,\n",
    "        \"judgment\": \"unanswered\",\n",
    "        \"text_span\", \"None\"\n",
    "    },\n",
    "    ...\n",
    "]\n",
    "\n",
    "Place the JSON-format response between <answer> and </answer> tags.\n",
    "\n",
    "Here are a few examples you can use for reference:\n",
    "\n",
    "$FEW-SHOT-EXAMPLES\n",
    "\n",
    "Passage: $PASSAGE\n",
    "List of questions: $LIST_OF_QUESTIONS\n",
    "Response in JSON-format: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe48edf2-ef7f-402b-b888-4c459edf53ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HARD = ['Article1', 'Article2', 'Article3', 'Article4', 'Article5']\n",
    "def prepare_few_shot_examples():\n",
    "    all_examples = list()\n",
    "    for tab in HARD:\n",
    "        df = raw_data[tab]\n",
    "        list_of_questions = df['Sub-Question'].tolist()\n",
    "        for rag_sys in [\"You.com\", \"Perplexity.ai\"]:\n",
    "            passage = df[rag_sys][0].replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "            example_response = list()\n",
    "            for _, row in df.iterrows():\n",
    "                question = row[\"Sub-Question\"]\n",
    "                judgment = row[f\"{rag_sys}-judgment\"]\n",
    "                assert judgment in [\"answered\", \"unanswered\"], print(tab, rag_sys, _, judgment)\n",
    "                text_span = \"None\" if judgment == \"unanswered\" else row[rag_sys][row[rag_sys].index(\"[\")+1:row[rag_sys].index(\"]\")]\n",
    "                example_response.append({\"question\": question, \"judgment\": judgment, \"text_span\": text_span})\n",
    "            example = \"Passage: $PASSAGE\\nList of questions: $LIST_OF_QUESTIONS\\nResponse in JSON-format: $RESPONSE_IN_JSON_FORMAT\"\n",
    "            example = example.replace(\"$PASSAGE\", passage).replace(\"$LIST_OF_QUESTIONS\", json.dumps(list_of_questions, indent=4)).replace(\"$RESPONSE_IN_JSON_FORMAT\", json.dumps(example_response, indent=4))\n",
    "            all_examples.append(example)\n",
    "    return \"\\n\\n\".join(all_examples)\n",
    "\n",
    "few_shot_examples = prepare_few_shot_examples()\n",
    "\n",
    "def subq_coverage_measurement(passage, list_of_questions):\n",
    "    raw_pred, _ = gpt4(prompt_template.replace(\"$PASSAGE\", passage).replace(\"$LIST_OF_QUESTIONS\", json.dumps(list_of_questions, indent=4)).replace(\"$FEW-SHOT-EXAMPLES\", few_shot_examples))\n",
    "    try:\n",
    "        parsed_pred = json.loads(raw_pred.replace(\"<answer>\", \"\").replace(\"</answer>\", \"\").strip())\n",
    "    except:\n",
    "        parsed_pred = None\n",
    "    return parsed_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
