{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494dc5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from pprint import pprint\n",
    "import re\n",
    "import copy\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1476faa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "import time\n",
    "SLEEP_TIME = 1\n",
    "\n",
    "def gpt4(input_text, prior_messages=None):\n",
    "    gpt4_kwargs = {\n",
    "        \"model\": \"gpt-4-turbo\",\n",
    "        \"temperature\": 0,\n",
    "    }\n",
    "    if prior_messages is None:\n",
    "        messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\n",
    "    else:\n",
    "        messages = copy.deepcopy(prior_messages)\n",
    "    messages.append({\"role\": \"user\", \"content\": input_text})\n",
    "    while True:\n",
    "        try:\n",
    "            response = client.chat.completions.create(messages=messages, **gpt4_kwargs)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(\"-\"*30)\n",
    "            print(e)\n",
    "            if type(e).__name__ == \"RateLimitError\":\n",
    "                print(f\"Sleep for {SLEEP_TIME}......\")\n",
    "                time.sleep(SLEEP_TIME)\n",
    "            print(\"-\"*30)\n",
    "    output_text = response.choices[0].message.content\n",
    "    messages.append({\"role\": \"assistant\", \"content\": output_text})\n",
    "    return output_text, messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a6c2c6-c461-4e8c-bc6f-37da230231d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "measured_person = [\"PERSON-1\", \"PERSON-2\", \"PERSON-3\", \"PERSON-4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44bb853-8b2d-41d6-991d-f465cbdf469e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    excel_file = pd.ExcelFile(path)\n",
    "    sheet_names = excel_file.sheet_names\n",
    "    all_sheets_data = {sheet: excel_file.parse(sheet) for sheet in sheet_names}\n",
    "    return all_sheets_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d02dff6-c3c0-43ef-8ccb-dc2f821b6b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = load_data(\"annotation_merged_v2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3039d85c-c03f-4152-98a0-dfea82e78dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Based on the sub-questionâ€™s relevance and functional role in answering the complex question, classify the sub-question into three types: core, background, and follow-up.\n",
    "\n",
    "The definitions of these three sub-question types are:\n",
    "(1) Core sub-questions:\n",
    " - They are central to the main topic and directly or partially address the complex question.\n",
    " - They are crucial for interpreting the logical reasoning of the complex question and provide essential insights required for answering the complex question.\n",
    " - They often involve multiple steps or perspectives, making them fundamental to generating a comprehensive and well-rounded response to the complex question.\n",
    "(2) Background sub-questions:\n",
    " - They are optional when answering the complex question, but they can provide additional context or background information that helps clarify the complex question.\n",
    " - Their primary role is to support the understanding of the main topic by offering supplementary evidence or information, though it is not strictly necessary for addressing the core aspects of the complex question.\n",
    "(3) Follow-up sub-questions:\n",
    " - They are not needed to answer the complex question.\n",
    " - They often arise after users receive an initial answer and seek further clarification or details.\n",
    " - They may explore specific aspects of the response in greater depth, but their answers can sometimes be out-of-scope or beyond the focus of the original complex question.\n",
    "\n",
    "Organize the answer in JSON-format, shaped as {\"type\": \"core\"}, {\"type\": \"background\"}, or {\"type\": \"follow-up\"}.\n",
    "Place the JSON-format answer between <answer> and </answer> tags.\n",
    "\n",
    "Here are a few examples you can use for reference:\n",
    "\n",
    "$FEW-SHOT-EXAMPLES\n",
    "\n",
    "Complex question: $QUESTION\n",
    "Its sub-question: $SUB-QUESTION\n",
    "Answer in JSON-format:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe48edf2-ef7f-402b-b888-4c459edf53ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_vote(row):\n",
    "    values, counts = np.unique(row, return_counts=True)\n",
    "    max_count_index = np.argmax(counts)\n",
    "    return values[max_count_index]\n",
    "\n",
    "for i in range(1, 11):\n",
    "    df = raw_data[f\"q{i}\"]\n",
    "    df['Question'] = df['Question'][0]\n",
    "    df['majority_vote'] = df[['PERSON-1', 'PERSON-2', 'PERSON-3', 'PERSON-4']].apply(majority_vote, axis=1)\n",
    "\n",
    "HARD = [\"q1\", \"q2\", \"q3\", \"q4\", \"q5\", \"q6\", \"q7\", \"q8\", \"q9\", \"q10\"]\n",
    "def prepare_few_shot_examples():\n",
    "    all_examples = list()\n",
    "    for tab in HARD:\n",
    "        df = raw_data[tab]\n",
    "        for _, row in df.iterrows():\n",
    "            question = row[\"Question\"]\n",
    "            sub_question = row[\"Sub-Question\"]\n",
    "            label = row[\"majority_vote\"]\n",
    "            example = \"Complex question: $QUESTION\\nIts sub-question: $SUB-QUESTION\\nAnswer in JSON-format: \\{\\\"type\\\": \\\"$LABEL\\\"\\}\"\n",
    "            example = example.replace(\"$QUESTION\", question).replace(\"$SUB-QUESTION\", sub_question).replace(\"$LABEL\", label)\n",
    "            all_examples.append(example)\n",
    "    return \"\\n\\n\".join(all_examples)\n",
    "\n",
    "few_shot_examples = prepare_few_shot_examples()\n",
    "\n",
    "def prompt(question, sub_question):\n",
    "    raw_pred, _ = gpt4(prompt_template.replace(\"$QUESTION\", question).replace(\"$SUB-QUESTION\", sub_question).replace(\"$FEW-SHOT-EXAMPLES\", few_shot_examples))\n",
    "    try:\n",
    "        parsed_pred = json.loads(raw_pred.replace(\"<answer>\", \"\").replace(\"</answer>\", \"\").strip())\n",
    "        prediction = parsed_pred[\"type\"]\n",
    "    except:\n",
    "        print(raw_pred)\n",
    "        prediction = \"None\"\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9feae9be-ce23-4627-8a9d-d9da4b40e949",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"decompositions.json\", \"r\") as f:\n",
    "    question_dataset = json.load(f)\n",
    "\n",
    "question_dataset_with_type = list()\n",
    "for sample in tqdm(question_dataset):\n",
    "    question = sample[\"question\"]\n",
    "    sample_with_type = {\"question\": question, \"sub_questions_with_types\": []}\n",
    "    for sub_question in sample[\"sub_questions\"]:\n",
    "        sub_q_type = prompt(question, sub_question)\n",
    "        sample_with_type[\"sub_questions_with_types\"].append({\"sub_question\": sub_question, \"type\": sub_q_type})\n",
    "    question_dataset_with_type.append(sample_with_type)\n",
    "\n",
    "with open(\"decompositions_with_type.json\", \"w\") as f:\n",
    "    json.dump(question_dataset_with_type, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
